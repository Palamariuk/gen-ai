{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 90189,
     "databundleVersionId": 10460083,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:30:40.419611Z",
     "iopub.execute_input": "2025-01-16T21:30:40.419948Z",
     "iopub.status.idle": "2025-01-16T21:30:40.424883Z",
     "shell.execute_reply.started": "2025-01-16T21:30:40.419920Z",
     "shell.execute_reply": "2025-01-16T21:30:40.423701Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:41.273955Z",
     "start_time": "2025-01-19T08:49:36.539252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engineer/anaconda/envs/palamariuk-genai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:41.290950Z",
     "start_time": "2025-01-19T08:49:41.289019Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# BASE_PATH = '/kaggle/input/gen-ai-ucu-2024-task-3'\n",
    "BASE_PATH = '../data'"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:13:29.485773Z",
     "iopub.execute_input": "2025-01-16T21:13:29.486104Z",
     "iopub.status.idle": "2025-01-16T21:13:29.490169Z",
     "shell.execute_reply.started": "2025-01-16T21:13:29.486078Z",
     "shell.execute_reply": "2025-01-16T21:13:29.489341Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:41.343894Z",
     "start_time": "2025-01-19T08:49:41.341939Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:41.462344Z",
     "start_time": "2025-01-19T08:49:41.393746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_json(f\"{BASE_PATH}/zno.train.jsonl\", lines=True)\n",
    "test_df = pd.read_json(f\"{BASE_PATH}/zno.test.jsonl\", lines=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"unsloth/Qwen2.5-7B\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # \"unsloth/Qwen2.5-0.5B\", \"unsloth/Qwen2.5-1.5B\", \"unsloth/Qwen2.5-3B\"\n",
    "    # \"unsloth/Qwen2.5-14B\",  \"unsloth/Qwen2.5-32B\",  \"unsloth/Qwen2.5-72B\",\n",
    "    model_name = MODEL_NAME,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T20:51:24.247089Z",
     "iopub.execute_input": "2025-01-16T20:51:24.247426Z",
     "iopub.status.idle": "2025-01-16T20:51:46.376535Z",
     "shell.execute_reply.started": "2025-01-16T20:51:24.247398Z",
     "shell.execute_reply": "2025-01-16T20:51:46.375353Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:49.321519Z",
     "start_time": "2025-01-19T08:49:41.787730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.1.5: Fast Qwen2 patching. Transformers: 4.48.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T20:51:52.133160Z",
     "iopub.execute_input": "2025-01-16T20:51:52.133609Z",
     "iopub.status.idle": "2025-01-16T20:51:58.548507Z",
     "shell.execute_reply.started": "2025-01-16T20:51:52.133571Z",
     "shell.execute_reply": "2025-01-16T20:51:58.547761Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:52.237056Z",
     "start_time": "2025-01-19T08:49:49.341063Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.1.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:52.274095Z",
     "start_time": "2025-01-19T08:49:52.270750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to preprocess your dataset\n",
    "def prepare_dpo_data(dataset):\n",
    "    pairs = []\n",
    "    for idx, record in dataset.iterrows():\n",
    "        question = record[\"question\"]\n",
    "        correct_answer_marker = record[\"correct_answers\"][0]\n",
    "        answers = {answer[\"marker\"]: answer[\"text\"] for answer in record[\"answers\"]}\n",
    "        options = '\\n'.join([f\"({marker}) {text}\" for marker, text in answers.items()])\n",
    "\n",
    "        try:\n",
    "            correct_answer = f\"({correct_answer_marker}) {answers[correct_answer_marker]}\"\n",
    "            incorrect_answer_marker = random.choice([marker for marker in answers.keys() if marker != correct_answer_marker])\n",
    "            incorrect_answer = f\"({incorrect_answer_marker}) {answers[incorrect_answer_marker]}\"\n",
    "        except:\n",
    "            correct_answer = f\"({correct_answer_marker})\"\n",
    "            incorrect_answer = \"\"\n",
    "\n",
    "        pairs.append({\n",
    "            \"prompt\": f\"{question}\\nOptions:\\n{options}\",\n",
    "            \"chosen\": correct_answer,\n",
    "            \"rejected\": incorrect_answer\n",
    "        })\n",
    "\n",
    "    return pairs"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:52.329330Z",
     "start_time": "2025-01-19T08:49:52.327178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dpo_loss(preferred_logits, non_preferred_logits):\n",
    "    \"\"\"Calculates the DPO loss for a pair of preferred and non-preferred logits.\"\"\"\n",
    "    return -torch.log(torch.exp(preferred_logits) / (torch.exp(preferred_logits) + torch.exp(non_preferred_logits))).mean()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:52.512697Z",
     "start_time": "2025-01-19T08:49:52.382086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dpo_data = prepare_dpo_data(dataset=train_df)\n",
    "dpo_df = pd.DataFrame(data=dpo_data)\n",
    "train_dataset_dpo = Dataset.from_pandas(dpo_df)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:52.546381Z",
     "start_time": "2025-01-19T08:49:52.544470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import DPOTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:52.676855Z",
     "start_time": "2025-01-19T08:49:52.637775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_kwargs = None\n",
    "ref_model = None\n",
    "ref_model_kwargs = None\n",
    "model_adapter_name = None\n",
    "ref_adapter_name = None\n",
    "\n",
    "output_dir = './model-dpo/'\n",
    "beta = 0.1\n",
    "max_seq_length = 128\n",
    "max_prompt_length = 128\n",
    "loss_type = \"sigmoid\" # \"hinge\" \"ipo\"  \"kto_pair\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size= 2,\n",
    "    gradient_accumulation_steps= 4,\n",
    "    warmup_ratio= 0.3,\n",
    "    num_train_epochs= 3,\n",
    "    learning_rate= 2e-4,\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    logging_steps= 20,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    seed = 3407,\n",
    "    output_dir=output_dir,\n",
    "    report_to=\"none\",\n",
    "    save_steps= 200,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    do_eval=False,\n",
    "    group_by_length= False,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engineer/anaconda/envs/palamariuk-genai/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T08:49:58.111231Z",
     "start_time": "2025-01-19T08:49:52.695442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model,\n",
    "\n",
    "    model_init_kwargs=model_kwargs,\n",
    "    ref_model_init_kwargs=ref_model_kwargs,\n",
    "\n",
    "    args=training_arguments,\n",
    "    beta=beta,\n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    train_dataset=train_dataset_dpo,\n",
    "    eval_dataset=train_dataset_dpo,\n",
    "    loss_type=loss_type,\n",
    "\n",
    "    max_length=512,\n",
    "    max_target_length=256,\n",
    "    max_prompt_length=128,\n",
    "\n",
    "    model_adapter_name=model_adapter_name,\n",
    "    ref_adapter_name=ref_adapter_name,\n",
    ")\n",
    "trainer.accelerator.print(f\"{trainer.model}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engineer/anaconda/envs/palamariuk-genai/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Extracting prompt from train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3063/3063 [00:00<00:00, 20327.00 examples/s]\n",
      "Applying chat template to train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3063/3063 [00:00<00:00, 34356.92 examples/s]\n",
      "Extracting prompt from eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3063/3063 [00:00<00:00, 27068.75 examples/s]\n",
      "Applying chat template to eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3063/3063 [00:00<00:00, 34117.69 examples/s]\n",
      "Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3063/3063 [00:02<00:00, 1324.71 examples/s]\n",
      "Tokenizing eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3063/3063 [00:02<00:00, 1327.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(152064, 3584, padding_idx=151665)\n",
      "        (layers): ModuleList(\n",
      "          (0-27): 28 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T10:38:08.806193Z",
     "start_time": "2025-01-19T08:50:02.945577Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_stats = trainer.train()",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,063 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 1,149\n",
      " \"-____-\"     Number of trainable parameters = 40,370,176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1149' max='1149' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1149/1149 1:47:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.619891</td>\n",
       "      <td>0.326793</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.640946</td>\n",
       "      <td>0.259988</td>\n",
       "      <td>-16.238506</td>\n",
       "      <td>-19.272909</td>\n",
       "      <td>-2.087404</td>\n",
       "      <td>-2.105130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.682900</td>\n",
       "      <td>0.543439</td>\n",
       "      <td>-0.367319</td>\n",
       "      <td>-0.950133</td>\n",
       "      <td>0.725103</td>\n",
       "      <td>0.582814</td>\n",
       "      <td>-23.179632</td>\n",
       "      <td>-29.442291</td>\n",
       "      <td>-1.898244</td>\n",
       "      <td>-1.927020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.407585</td>\n",
       "      <td>-0.328287</td>\n",
       "      <td>-1.458135</td>\n",
       "      <td>0.841710</td>\n",
       "      <td>1.129847</td>\n",
       "      <td>-22.789312</td>\n",
       "      <td>-34.522308</td>\n",
       "      <td>-2.325773</td>\n",
       "      <td>-2.355011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.242782</td>\n",
       "      <td>-1.808381</td>\n",
       "      <td>-7.235130</td>\n",
       "      <td>0.908943</td>\n",
       "      <td>5.426749</td>\n",
       "      <td>-37.590248</td>\n",
       "      <td>-92.292267</td>\n",
       "      <td>-1.729807</td>\n",
       "      <td>-1.986972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.091657</td>\n",
       "      <td>-0.958821</td>\n",
       "      <td>-6.977176</td>\n",
       "      <td>0.968016</td>\n",
       "      <td>6.018354</td>\n",
       "      <td>-29.094645</td>\n",
       "      <td>-89.712715</td>\n",
       "      <td>-1.533589</td>\n",
       "      <td>-1.645666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T10:38:38.971756Z",
     "start_time": "2025-01-19T10:38:37.807512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"lora_model_dpo\") # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model_dpo\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model_dpo/tokenizer_config.json',\n",
       " 'lora_model_dpo/special_tokens_map.json',\n",
       " 'lora_model_dpo/vocab.json',\n",
       " 'lora_model_dpo/merges.txt',\n",
       " 'lora_model_dpo/added_tokens.json',\n",
       " 'lora_model_dpo/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "1 == 1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T11:05:29.534796Z",
     "start_time": "2025-01-19T11:05:29.531788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zno_prompt = \"\"\"Below is a question about Ukrainian history, language and literature. Select the correct answer marker from the provided options. Example output: [A]\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Options:\n",
    "{}\n",
    "\n",
    "### Correct Answer:\n",
    "{}\"\"\""
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T11:05:29.810542Z",
     "start_time": "2025-01-19T11:05:29.806768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def solve_task(row):\n",
    "    import re\n",
    "    question = row['question']\n",
    "    options = ','.join([f\"[{option['marker']}] {option['text']}\" for option in row['answers']])\n",
    "\n",
    "    inputs = tokenizer([zno_prompt.format(question, options, \"[\",)], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=3, use_cache=True)\n",
    "    outputs = tokenizer.batch_decode(outputs)\n",
    "\n",
    "    result = outputs[0].split('Correct Answer:\\n[')[1][0]\n",
    "    return result\n",
    "    # match = re.search(r\"### Correct Answer:\\s*\\[([A-Za-z–ê-–Ø–∞-—è0-9])\\]\", outputs[0])\n",
    "    # result = match.group(1)\n",
    "    # return [result]"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    zno_prompt.format(\n",
    "        '–ü–æ–∑–Ω–∞—á—Ç–µ —Ä—è–¥–æ–∫, —É —è–∫–æ–º—É –≤ —É—Å—ñ—Ö —Å–ª–æ–≤–∞—Ö –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø–∏—Å–∞—Ç–∏ –ª—ñ—Ç–µ—Ä—É *–∏*', # instruction\n",
    "        '(–ê) –±–∞–¥..–ª–∏–Ω–∞, –±–ª–∞–≥–æ—á..—Å—Ç–∏–≤–∏–π, –∫—Ä..—Ö–∫–∏–π, –∂..–≤–∏—Ü—è;,(–ë) –≤–∞—Ä..–≤–æ, –º–µ–∂..—Ä—ñ—á—á—è, –≤–∏—á..–ø—É—Ä–µ–Ω–∏–π, –∫—Ä..—à—Ç–∞–ª—å;,(–í) –ø‚Äô—è—Ç..—Ä—ñ—á–∫–∞, –∑–∞—Ä—É—á..–Ω–∏, –Ω–µ–≤..–¥–∏–º–∫–∞, –æ–±—ñ—Ç–Ω..—Ü—è;,(–ì) –∑–∞—á..–Ω–∞—Ç–∏, –≤–∏–∫–æ–Ω–∞–≤..—Ü—è, –∑–Ω—ñ–≤..—á–∏—Ç–∏, –≤–µ–ª..—á–∏–Ω–∞;,(–î) –Ω–æ–∂..—á–æ–∫, –ø–µ—á..–≤–æ, –≤–∏–∫–æ—Ä..–Ω–∏—Ç–∏, –æ–∑..—Ä–∞—Ç–∏—Å—è.', # input\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 3, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:01:31.223885Z",
     "iopub.execute_input": "2025-01-16T21:01:31.224276Z",
     "iopub.status.idle": "2025-01-16T21:01:31.831786Z",
     "shell.execute_reply.started": "2025-01-16T21:01:31.224228Z",
     "shell.execute_reply": "2025-01-16T21:01:31.831060Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T11:05:31.065104Z",
     "start_time": "2025-01-19T11:05:30.886565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is a question about Ukrainian history, language and literature. Select the correct answer marker from the provided options. Example output: [A]\\n\\n### Question:\\n–ü–æ–∑–Ω–∞—á—Ç–µ —Ä—è–¥–æ–∫, —É —è–∫–æ–º—É –≤ —É—Å—ñ—Ö —Å–ª–æ–≤–∞—Ö –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø–∏—Å–∞—Ç–∏ –ª—ñ—Ç–µ—Ä—É *–∏*\\n\\n### Options:\\n(–ê) –±–∞–¥..–ª–∏–Ω–∞, –±–ª–∞–≥–æ—á..—Å—Ç–∏–≤–∏–π, –∫—Ä..—Ö–∫–∏–π, –∂..–≤–∏—Ü—è;,(–ë) –≤–∞—Ä..–≤–æ, –º–µ–∂..—Ä—ñ—á—á—è, –≤–∏—á..–ø—É—Ä–µ–Ω–∏–π, –∫—Ä..—à—Ç–∞–ª—å;,(–í) –ø‚Äô—è—Ç..—Ä—ñ—á–∫–∞, –∑–∞—Ä—É—á..–Ω–∏, –Ω–µ–≤..–¥–∏–º–∫–∞, –æ–±—ñ—Ç–Ω..—Ü—è;,(–ì) –∑–∞—á..–Ω–∞—Ç–∏, –≤–∏–∫–æ–Ω–∞–≤..—Ü—è, –∑–Ω—ñ–≤..—á–∏—Ç–∏, –≤–µ–ª..—á–∏–Ω–∞;,(–î) –Ω–æ–∂..—á–æ–∫, –ø–µ—á..–≤–æ, –≤–∏–∫–æ—Ä..–Ω–∏—Ç–∏, –æ–∑..—Ä–∞—Ç–∏—Å—è.\\n\\n### Correct Answer:\\n(–í)']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['correct_answers'] = test_df.progress_apply(solve_task, axis=1)\n",
    "submission_df"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:25:47.930730Z",
     "iopub.execute_input": "2025-01-16T21:25:47.931063Z",
     "iopub.status.idle": "2025-01-16T21:25:47.955027Z",
     "shell.execute_reply.started": "2025-01-16T21:25:47.931035Z",
     "shell.execute_reply": "2025-01-16T21:25:47.954252Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T10:59:35.897618Z",
     "start_time": "2025-01-19T10:57:16.519292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [02:19<00:00,  5.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                              question  \\\n",
       "0    ¬´–°–º—ñ—Ö–æ–º –∫—Ä—ñ–∑—å —Å–ª—å–æ–∑–∏¬ª –º–æ–∂–Ω–∞ —Å—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–≤–∞—Ç–∏ –∑...   \n",
       "1    –£–¥–æ–≤–∏–Ω —Å–∏–Ω, –º–∞—Ç–∏, —Å–µ—Å—Ç—Ä–∞, –∫–æ—Ö–∞–Ω–∞ ‚Äì –∫–ª—é—á–æ–≤—ñ –æ–±—Ä...   \n",
       "2    –í —É—Ä–∏–≤–∫—É –∑ —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ ¬´*–°—Ç–≤–æ—Ä–∏–≤—à–∏ –±–∞–Ω...   \n",
       "3    –í —É—Ä–∏–≤–∫—É\\n\\n\\n*–î–æ–∫–∏ –±—É–¥–µ –∂–∏—Ç–∏ –£–∫—Ä–∞—ó–Ω–∞\\n\\n–í —Ç–µ–ø...   \n",
       "4    –ë—É–∫–≤—É ***–∏*** –Ω–∞ –º—ñ—Å—Ü—ñ –ø—Ä–æ–ø—É—Å–∫—É —Ç—Ä–µ–±–∞ –ø–∏—Å–∞—Ç–∏ –≤...   \n",
       "..                                                 ...   \n",
       "746  –£–∫–∞–∂—ñ—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç¬†–ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ–≥–æ –∑–∞–ø–æ–≤–Ω...   \n",
       "747  **–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π—Ç–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞...   \n",
       "748  –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ —Ä–µ—á–µ–Ω–Ω—è *(—Ü–∏—Ñ—Ä–∞ –ø–æ–∑–Ω–∞—á–∞—î –Ω–∞—Å—Ç—É–ø–Ω–µ —Å...   \n",
       "749  –ì—Ä–∞–º–∞—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–µ –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è —Ä–µ—á–µ–Ω–Ω—è ¬´*–ü–µ—Ä...   \n",
       "750  –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ —É—Ä–∏–≤–æ–∫ –¥–∂–µ—Ä–µ–ª–∞.\\n\\n\\n¬´*–£ –ú–æ—Å–∫–æ–≤—â–∏–Ω—ñ...   \n",
       "\n",
       "                                               answers  \\\n",
       "0    [{'marker': '–ê', 'text': '¬´–¢—Ä–∏ –∑–æ–∑—É–ª—ñ –∑ –ø–æ–∫–ª–æ–Ω...   \n",
       "1    [{'marker': '–ê', 'text': '¬´–ó–∞—Å–≤—ñ—Ç –≤—Å—Ç–∞–ª–∏ –∫–æ–∑–∞—á...   \n",
       "2    [{'marker': '–ê', 'text': '–ü—Ä–∞–≤–æ–±–µ—Ä–µ–∂–Ω–æ—ó –£–∫—Ä–∞—ó–Ω...   \n",
       "3    [{'marker': '–ê', 'text': '–í–∞—Å–∏–ª—è –°—Ç–µ—Ñ–∞–Ω–∏–∫–∞'}, ...   \n",
       "4    [{'marker': '–ê', 'text': '–ø—Ä‚Ä¶.—Ö–æ–≤–∞–Ω–∏–π, –ø—Ä‚Ä¶–∑–≤–∏—Å...   \n",
       "..                                                 ...   \n",
       "746  [{'marker': '–ê', 'text': '–¥—ñ—î–≤–∏—Ö –ø—Ä–∏–π–æ–º—ñ–≤, —è–∫—ñ...   \n",
       "747  [{'marker': '–ê', 'text': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –≥–æ–ª–æ–≤–Ω–∞ –≤...   \n",
       "748  [{'marker': '–ê', 'text': '3, 4, 5, 10'}, {'mar...   \n",
       "749  [{'marker': '–ê', 'text': '–º–µ–Ω—ñ –ø—Ä–∏–≥–∞–¥–∞–ª–∏—Å—è –¥–∞–≤...   \n",
       "750  [{'marker': '–ê', 'text': '–ó–±–æ—Ä—ñ–≤—Å—å–∫–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä...   \n",
       "\n",
       "                               subject   id correct_answers  \n",
       "0    ukrainian-language-and-literature    0               –ë  \n",
       "1    ukrainian-language-and-literature    1               –í  \n",
       "2                   history-of-ukraine    2               –ì  \n",
       "3    ukrainian-language-and-literature    3               –ë  \n",
       "4    ukrainian-language-and-literature    4               –í  \n",
       "..                                 ...  ...             ...  \n",
       "746  ukrainian-language-and-literature  746               –ì  \n",
       "747                 history-of-ukraine  747               –ì  \n",
       "748  ukrainian-language-and-literature  748               –ë  \n",
       "749  ukrainian-language-and-literature  749               –ê  \n",
       "750                 history-of-ukraine  750               –ì  \n",
       "\n",
       "[751 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>subject</th>\n",
       "      <th>id</th>\n",
       "      <th>correct_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¬´–°–º—ñ—Ö–æ–º –∫—Ä—ñ–∑—å —Å–ª—å–æ–∑–∏¬ª –º–æ–∂–Ω–∞ —Å—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–≤–∞—Ç–∏ –∑...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '¬´–¢—Ä–∏ –∑–æ–∑—É–ª—ñ –∑ –ø–æ–∫–ª–æ–Ω...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>0</td>\n",
       "      <td>–ë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–£–¥–æ–≤–∏–Ω —Å–∏–Ω, –º–∞—Ç–∏, —Å–µ—Å—Ç—Ä–∞, –∫–æ—Ö–∞–Ω–∞ ‚Äì –∫–ª—é—á–æ–≤—ñ –æ–±—Ä...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '¬´–ó–∞—Å–≤—ñ—Ç –≤—Å—Ç–∞–ª–∏ –∫–æ–∑–∞—á...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>1</td>\n",
       "      <td>–í</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–í —É—Ä–∏–≤–∫—É –∑ —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ ¬´*–°—Ç–≤–æ—Ä–∏–≤—à–∏ –±–∞–Ω...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–ü—Ä–∞–≤–æ–±–µ—Ä–µ–∂–Ω–æ—ó –£–∫—Ä–∞—ó–Ω...</td>\n",
       "      <td>history-of-ukraine</td>\n",
       "      <td>2</td>\n",
       "      <td>–ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–í —É—Ä–∏–≤–∫—É\\n\\n\\n*–î–æ–∫–∏ –±—É–¥–µ –∂–∏—Ç–∏ –£–∫—Ä–∞—ó–Ω–∞\\n\\n–í —Ç–µ–ø...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–í–∞—Å–∏–ª—è –°—Ç–µ—Ñ–∞–Ω–∏–∫–∞'}, ...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>3</td>\n",
       "      <td>–ë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ë—É–∫–≤—É ***–∏*** –Ω–∞ –º—ñ—Å—Ü—ñ –ø—Ä–æ–ø—É—Å–∫—É —Ç—Ä–µ–±–∞ –ø–∏—Å–∞—Ç–∏ –≤...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–ø—Ä‚Ä¶.—Ö–æ–≤–∞–Ω–∏–π, –ø—Ä‚Ä¶–∑–≤–∏—Å...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>4</td>\n",
       "      <td>–í</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>–£–∫–∞–∂—ñ—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç¬†–ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ–≥–æ –∑–∞–ø–æ–≤–Ω...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–¥—ñ—î–≤–∏—Ö –ø—Ä–∏–π–æ–º—ñ–≤, —è–∫—ñ...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>746</td>\n",
       "      <td>–ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>**–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π—Ç–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –≥–æ–ª–æ–≤–Ω–∞ –≤...</td>\n",
       "      <td>history-of-ukraine</td>\n",
       "      <td>747</td>\n",
       "      <td>–ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>–ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ —Ä–µ—á–µ–Ω–Ω—è *(—Ü–∏—Ñ—Ä–∞ –ø–æ–∑–Ω–∞—á–∞—î –Ω–∞—Å—Ç—É–ø–Ω–µ —Å...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '3, 4, 5, 10'}, {'mar...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>748</td>\n",
       "      <td>–ë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>–ì—Ä–∞–º–∞—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–µ –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è —Ä–µ—á–µ–Ω–Ω—è ¬´*–ü–µ—Ä...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–º–µ–Ω—ñ –ø—Ä–∏–≥–∞–¥–∞–ª–∏—Å—è –¥–∞–≤...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>749</td>\n",
       "      <td>–ê</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>–ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ —É—Ä–∏–≤–æ–∫ –¥–∂–µ—Ä–µ–ª–∞.\\n\\n\\n¬´*–£ –ú–æ—Å–∫–æ–≤—â–∏–Ω—ñ...</td>\n",
       "      <td>[{'marker': '–ê', 'text': '–ó–±–æ—Ä—ñ–≤—Å—å–∫–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä...</td>\n",
       "      <td>history-of-ukraine</td>\n",
       "      <td>750</td>\n",
       "      <td>–ì</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows √ó 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "source": [
    "submission_df['correct_answers'] = submission_df['correct_answers'].apply(lambda x: x[0])\n",
    "submission_df[[\"id\", \"correct_answers\"]].to_csv(\"submission-dpo-3epoch.csv\", index=False)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:26:21.873889Z",
     "iopub.execute_input": "2025-01-16T21:26:21.874197Z",
     "iopub.status.idle": "2025-01-16T21:26:21.880935Z",
     "shell.execute_reply.started": "2025-01-16T21:26:21.874174Z",
     "shell.execute_reply": "2025-01-16T21:26:21.879772Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-19T10:59:48.061101Z",
     "start_time": "2025-01-19T10:59:48.055347Z"
    }
   },
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
