{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 90189,
     "databundleVersionId": 10460083,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:30:40.419611Z",
     "iopub.execute_input": "2025-01-16T21:30:40.419948Z",
     "iopub.status.idle": "2025-01-16T21:30:40.424883Z",
     "shell.execute_reply.started": "2025-01-16T21:30:40.419920Z",
     "shell.execute_reply": "2025-01-16T21:30:40.423701Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:56:00.040717Z",
     "start_time": "2025-01-17T18:55:55.907753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engineer/anaconda/envs/palamariuk-genai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:56:00.059359Z",
     "start_time": "2025-01-17T18:56:00.056743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# BASE_PATH = '/kaggle/input/gen-ai-ucu-2024-task-3'\n",
    "BASE_PATH = '../data'"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:13:29.485773Z",
     "iopub.execute_input": "2025-01-16T21:13:29.486104Z",
     "iopub.status.idle": "2025-01-16T21:13:29.490169Z",
     "shell.execute_reply.started": "2025-01-16T21:13:29.486078Z",
     "shell.execute_reply": "2025-01-16T21:13:29.489341Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:56:00.799784Z",
     "start_time": "2025-01-17T18:56:00.796973Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:56:01.330469Z",
     "start_time": "2025-01-17T18:56:01.259600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_json(f\"{BASE_PATH}/zno.train.jsonl\", lines=True)\n",
    "test_df = pd.read_json(f\"{BASE_PATH}/zno.test.jsonl\", lines=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # \"unsloth/Qwen2.5-0.5B\", \"unsloth/Qwen2.5-1.5B\", \"unsloth/Qwen2.5-3B\"\n",
    "    # \"unsloth/Qwen2.5-14B\",  \"unsloth/Qwen2.5-32B\",  \"unsloth/Qwen2.5-72B\",\n",
    "    model_name = \"unsloth/Qwen2.5-14B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T20:51:24.247089Z",
     "iopub.execute_input": "2025-01-16T20:51:24.247426Z",
     "iopub.status.idle": "2025-01-16T20:51:46.376535Z",
     "shell.execute_reply.started": "2025-01-16T20:51:24.247398Z",
     "shell.execute_reply": "2025-01-16T20:51:46.375353Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:56:11.129386Z",
     "start_time": "2025-01-17T18:56:01.774169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.1.5: Fast Qwen2 patching. Transformers: 4.48.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T20:51:52.133160Z",
     "iopub.execute_input": "2025-01-16T20:51:52.133609Z",
     "iopub.status.idle": "2025-01-16T20:51:58.548507Z",
     "shell.execute_reply.started": "2025-01-16T20:51:52.133571Z",
     "shell.execute_reply": "2025-01-16T20:51:58.547761Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:56:17.026563Z",
     "start_time": "2025-01-17T18:56:14.024792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.1.5 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:59:30.988016Z",
     "start_time": "2025-01-17T18:59:30.985018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zno_prompt = \"\"\"Below is a question about Ukrainian history, language and literature. Select the correct answer from the provided options.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Options:\n",
    "{}\n",
    "\n",
    "### Correct Answer:\n",
    "{}\"\"\""
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:59:33.738516Z",
     "start_time": "2025-01-17T18:59:33.716099Z"
    }
   },
   "cell_type": "code",
   "source": "FastLanguageModel.for_inference(model)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(152064, 5120, padding_idx=151665)\n",
       "        (layers): ModuleList(\n",
       "          (0-47): 48 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=5120, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=13824, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=13824, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=13824, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=13824, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((5120,), eps=1e-05)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((5120,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((5120,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=5120, out_features=152064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:59:36.028959Z",
     "start_time": "2025-01-17T18:59:34.844727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    zno_prompt.format(\n",
    "        'Позначте рядок, у якому в усіх словах потрібно писати літеру *и*', # instruction\n",
    "        '(А) бад..лина, благоч..стивий, кр..хкий, ж..виця;,(Б) вар..во, меж..річчя, вич..пурений, кр..шталь;,(В) п’ят..річка, заруч..ни, нев..димка, обітн..ця;,(Г) зач..нати, виконав..ця, знів..чити, вел..чина;,(Д) нож..чок, печ..во, викор..нити, оз..ратися.', # input\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 3, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is a question about Ukrainian history, language and literature. Select the correct answer from the provided options.\\n\\n### Question:\\nПозначте рядок, у якому в усіх словах потрібно писати літеру *и*\\n\\n### Options:\\n(А) бад..лина, благоч..стивий, кр..хкий, ж..виця;,(Б) вар..во, меж..річчя, вич..пурений, кр..шталь;,(В) п’ят..річка, заруч..ни, нев..димка, обітн..ця;,(Г) зач..нати, виконав..ця, знів..чити, вел..чина;,(Д) нож..чок, печ..во, викор..нити, оз..ратися.\\n\\n### Correct Answer:\\n(А)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:00:03.881262Z",
     "start_time": "2025-01-17T19:00:03.877909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def solve_task(row):\n",
    "    question = row['question']\n",
    "    options = ','.join([f\"[{option['marker']}] {option['text']}\" for option in row['answers']])\n",
    "\n",
    "    inputs = tokenizer([zno_prompt.format(question, options, \"\",)], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=3, use_cache=True)\n",
    "    outputs = tokenizer.batch_decode(outputs)\n",
    "    result = outputs[0].split(\"Correct Answer:\\n\")[1]\n",
    "    return [result[1]]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:00:33.662389Z",
     "start_time": "2025-01-17T19:00:04.502287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train2_df = train_df.iloc[:100].copy()\n",
    "train2_df['solution'] = train2_df.progress_apply(solve_task, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.43it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:00:48.021326Z",
     "start_time": "2025-01-17T19:00:48.015583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = 0\n",
    "for _, row in train2_df.iterrows():\n",
    "    if row['correct_answers'][0] == row['solution'][0]:\n",
    "        count+=1\n",
    "\n",
    "print(count)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:43:04.577898Z",
     "start_time": "2025-01-17T18:43:04.553766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatting_prompts_func(row):\n",
    "    question = row['question']\n",
    "    options = ','.join([f\"[{option['marker']}] {option['text']}\" for option in row['answers']])\n",
    "    correct_answer = f\"({row['correct_answers'][0]})\"\n",
    "\n",
    "    text = zno_prompt.format(question, options, correct_answer) +  tokenizer.eos_token\n",
    "    return text\n",
    "\n",
    "train2_df['text'] = train2_df.apply(formatting_prompts_func, axis=1)\n",
    "dataset = Dataset.from_pandas(train2_df)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:45:20.496520Z",
     "start_time": "2025-01-17T18:45:19.463435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = None,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████| 100/100 [00:00<00:00, 140.82 examples/s]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T18:45:57.076149Z",
     "start_time": "2025-01-17T18:45:21.046701Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_stats = trainer.train()",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 100 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 12\n",
      " \"-____-\"     Number of trainable parameters = 68,812,800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:31, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.308700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.455200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.663800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    zno_prompt.format(\n",
    "        'Позначте рядок, у якому в усіх словах потрібно писати літеру *и*', # instruction\n",
    "        '(А) бад..лина, благоч..стивий, кр..хкий, ж..виця;,(Б) вар..во, меж..річчя, вич..пурений, кр..шталь;,(В) п’ят..річка, заруч..ни, нев..димка, обітн..ця;,(Г) зач..нати, виконав..ця, знів..чити, вел..чина;,(Д) нож..чок, печ..во, викор..нити, оз..ратися.', # input\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 3, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:01:31.223885Z",
     "iopub.execute_input": "2025-01-16T21:01:31.224276Z",
     "iopub.status.idle": "2025-01-16T21:01:31.831786Z",
     "shell.execute_reply.started": "2025-01-16T21:01:31.224228Z",
     "shell.execute_reply": "2025-01-16T21:01:31.831060Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:44:00.857714Z",
     "start_time": "2025-01-17T18:44:00.550281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is a question related to the Ukrainian language and literature. Select the correct answer from the options provided.\\n\\n### Question:\\nПозначте рядок, у якому в усіх словах потрібно писати літеру *и*\\n\\n### Options:\\n(А) бад..лина, благоч..стивий, кр..хкий, ж..виця;,(Б) вар..во, меж..річчя, вич..пурений, кр..шталь;,(В) п’ят..річка, заруч..ни, нев..димка, обітн..ця;,(Г) зач..нати, виконав..ця, знів..чити, вел..чина;,(Д) нож..чок, печ..во, викор..нити, оз..ратися.\\n\\n### Correct Answer:\\n(В)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:42:35.570519Z",
     "start_time": "2025-01-17T16:42:35.541007Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.iloc[0].text",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is a task, paired with answer options. Solve the task and return the correct answer as an option letter.\\n\\n### Task:\\nПозначте рядок, у якому в усіх словах потрібно писати літеру *и*:\\n\\n### Options:\\n[А] бад..лина, благоч..стивий, кр..хкий, ж..виця;,[Б] вар..во, меж..річчя, вич..пурений, кр..шталь;,[В] п’ят..річка, заруч..ни, нев..димка, обітн..ця;,[Г] зач..нати, виконав..ця, знів..чити, вел..чина;,[Д] нож..чок, печ..во, викор..нити, оз..ратися.\\n\\n### The correct answer is:\\n(В)<|endoftext|>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:13:49.283454Z",
     "iopub.execute_input": "2025-01-16T21:13:49.283886Z",
     "iopub.status.idle": "2025-01-16T21:13:49.290698Z",
     "shell.execute_reply.started": "2025-01-16T21:13:49.283854Z",
     "shell.execute_reply": "2025-01-16T21:13:49.289836Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T16:42:36.083706Z",
     "start_time": "2025-01-17T16:42:36.076649Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:43:07.351334Z",
     "start_time": "2025-01-17T16:42:37.206209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train2_df = train_df.iloc[:100].copy()\n",
    "train2_df['solution'] = train2_df.progress_apply(solve_task, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:43:07.985164Z",
     "start_time": "2025-01-17T16:43:07.972685Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T12:49:13.409576Z",
     "start_time": "2025-01-17T12:49:13.406534Z"
    }
   },
   "cell_type": "code",
   "source": "705/3063",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23016650342801176"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T12:44:01.541901Z",
     "start_time": "2025-01-17T12:44:01.519752Z"
    }
   },
   "cell_type": "code",
   "source": "train_df[train_df[\"correct_answers\"] != train_df[\"solution\"]]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               question  \\\n",
       "0     Позначте рядок, у якому в усіх словах потрібно...   \n",
       "1     Позначте словосполучення, у якому порушено гра...   \n",
       "2     Позначте пару речень, у яких виділені слова є ...   \n",
       "3     Позначте речення, у якому одиничний дієприслів...   \n",
       "4     Позначте рядок, у якому фразеологічні звороти ...   \n",
       "...                                                 ...   \n",
       "3058  В уривку\\n\\n\\n*Тріщить, лящить, мов щелепа, ко...   \n",
       "3059  «*Як можна бути вільним, Евкріте, коли маєш ті...   \n",
       "3060  «*А вчора, пишучи спогади про дитинство, про х...   \n",
       "3061  Думка Г. Сковороди, що смерті не боїться «*той...   \n",
       "3062            Ознаки постмодернізму відчутні в рядках   \n",
       "\n",
       "                                                answers correct_answers  \\\n",
       "0     [{'marker': 'А', 'text': 'бад..лина, благоч..с...             [В]   \n",
       "1     [{'marker': 'А', 'text': 'рівно о першій;'}, {...             [Г]   \n",
       "2     [{'marker': 'А', 'text': '*Слово*, чому ти не ...             [Б]   \n",
       "3     [{'marker': 'А', 'text': 'Гуркіт канонади реві...             [Д]   \n",
       "4     [{'marker': 'А', 'text': 'на живу нитку – біли...             [Б]   \n",
       "...                                                 ...             ...   \n",
       "3058  [{'marker': 'А', 'text': 'антитеза'}, {'marker...             [Д]   \n",
       "3059  [{'marker': 'А', 'text': 'Степан Радченко й На...             [А]   \n",
       "3060  [{'marker': 'А', 'text': 'Юрій Яновський'}, {'...             [Б]   \n",
       "3061  [{'marker': 'А', 'text': 'Івана Шрама та Івана...             [Д]   \n",
       "3062  [{'marker': 'А', 'text': '«СЕРЦЕ, КИНУТЕ В ЮРБ...             [А]   \n",
       "\n",
       "                                subject solution  \n",
       "0     ukrainian-language-and-literature      [В]  \n",
       "1     ukrainian-language-and-literature      [Г]  \n",
       "2     ukrainian-language-and-literature      [В]  \n",
       "3     ukrainian-language-and-literature      [Г]  \n",
       "4     ukrainian-language-and-literature      [В]  \n",
       "...                                 ...      ...  \n",
       "3058  ukrainian-language-and-literature      [В]  \n",
       "3059  ukrainian-language-and-literature      [Г]  \n",
       "3060  ukrainian-language-and-literature      [А]  \n",
       "3061  ukrainian-language-and-literature      [Б]  \n",
       "3062  ukrainian-language-and-literature      [А]  \n",
       "\n",
       "[3063 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>correct_answers</th>\n",
       "      <th>subject</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Позначте рядок, у якому в усіх словах потрібно...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'бад..лина, благоч..с...</td>\n",
       "      <td>[В]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[В]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Позначте словосполучення, у якому порушено гра...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'рівно о першій;'}, {...</td>\n",
       "      <td>[Г]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Позначте пару речень, у яких виділені слова є ...</td>\n",
       "      <td>[{'marker': 'А', 'text': '*Слово*, чому ти не ...</td>\n",
       "      <td>[Б]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[В]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Позначте речення, у якому одиничний дієприслів...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Гуркіт канонади реві...</td>\n",
       "      <td>[Д]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Позначте рядок, у якому фразеологічні звороти ...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'на живу нитку – біли...</td>\n",
       "      <td>[Б]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[В]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>В уривку\\n\\n\\n*Тріщить, лящить, мов щелепа, ко...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'антитеза'}, {'marker...</td>\n",
       "      <td>[Д]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[В]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>«*Як можна бути вільним, Евкріте, коли маєш ті...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Степан Радченко й На...</td>\n",
       "      <td>[А]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>«*А вчора, пишучи спогади про дитинство, про х...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Юрій Яновський'}, {'...</td>\n",
       "      <td>[Б]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[А]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>Думка Г. Сковороди, що смерті не боїться «*той...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Івана Шрама та Івана...</td>\n",
       "      <td>[Д]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[Б]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>Ознаки постмодернізму відчутні в рядках</td>\n",
       "      <td>[{'marker': 'А', 'text': '«СЕРЦЕ, КИНУТЕ В ЮРБ...</td>\n",
       "      <td>[А]</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>[А]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3063 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T12:18:06.116629Z",
     "start_time": "2025-01-17T12:18:04.485614Z"
    }
   },
   "cell_type": "code",
   "source": "test_df.iloc[:5].progress_apply(solve_task, axis=1)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [В]\n",
       "1    [В]\n",
       "2    [Б]\n",
       "3    [В]\n",
       "4    [А]\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T12:16:12.094058Z",
     "start_time": "2025-01-17T12:16:12.060198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for row in train_df.iloc[:5].iterrows():\n",
    "    print(solve_task(row))"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m train_df\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m5\u001B[39m]\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43msolve_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[12], line 2\u001B[0m, in \u001B[0;36msolve_task\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msolve_task\u001B[39m(row):\n\u001B[0;32m----> 2\u001B[0m     question \u001B[38;5;241m=\u001B[39m \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mquestion\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      3\u001B[0m     options \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moption[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmarker\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moption[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m option \u001B[38;5;129;01min\u001B[39;00m train_df\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124manswers\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[1;32m      5\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m tokenizer([zno_prompt\u001B[38;5;241m.\u001B[39mformat(question, options, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,)], return_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "test_df[\"corrected_answers\"] = test_df.apply(solve_task, axis=1)\ntest_df",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:31:32.475465Z",
     "iopub.execute_input": "2025-01-16T21:31:32.475770Z",
     "iopub.status.idle": "2025-01-16T21:31:39.597183Z",
     "shell.execute_reply.started": "2025-01-16T21:31:32.475730Z",
     "shell.execute_reply": "2025-01-16T21:31:39.595852Z"
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-70-f58335bd79ad>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"corrected_answers\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msolve_task\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtest_df\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m  10372\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10373\u001B[0m         )\n\u001B[0;32m> 10374\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"apply\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  10375\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10376\u001B[0m     def map(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    914\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine_kwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    915\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 916\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    917\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    918\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1061\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1062\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1063\u001B[0;31m             \u001B[0mresults\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1064\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1065\u001B[0m             \u001B[0mresults\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_series_numba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1079\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1080\u001B[0m                 \u001B[0;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1081\u001B[0;31m                 \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1082\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1083\u001B[0m                     \u001B[0;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-60-d0f52258ca4f>\u001B[0m in \u001B[0;36msolve_task\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mzno_prompt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"pt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"cuda\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_new_tokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_cache\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"The correct answer is:\\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    114\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mctx_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 116\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    117\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001B[0m in \u001B[0;36m_fast_generate\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1502\u001B[0m         \u001B[0;31m# Autocasted\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1503\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautocast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdevice_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1504\u001B[0;31m             \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1505\u001B[0m         \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1836\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_enable_peft_forward_hooks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1837\u001B[0m                     \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspecial_peft_forward_args\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1838\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1839\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1840\u001B[0m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    114\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mctx_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 116\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    117\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   2253\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2254\u001B[0m             \u001B[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2255\u001B[0;31m             result = self._sample(\n\u001B[0m\u001B[1;32m   2256\u001B[0m                 \u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2257\u001B[0m                 \u001B[0mlogits_processor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprepared_logits_processor\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001B[0m in \u001B[0;36m_sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3241\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3242\u001B[0m         \u001B[0mis_prefill\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3243\u001B[0;31m         while self._has_unfinished_sequences(\n\u001B[0m\u001B[1;32m   3244\u001B[0m             \u001B[0mthis_peer_finished\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msynced_gpus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_len\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcur_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_length\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3245\u001B[0m         ):\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001B[0m in \u001B[0;36m_has_unfinished_sequences\u001B[0;34m(self, this_peer_finished, synced_gpus, device, cur_len, max_length)\u001B[0m\n\u001B[1;32m   2451\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mthis_peer_finished_flag\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2452\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2453\u001B[0;31m             \u001B[0;32melif\u001B[0m \u001B[0mthis_peer_finished\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2454\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2455\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['correct_answers'] = test_df.progress_apply(solve_task, axis=1)\n",
    "submission_df"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:25:47.930730Z",
     "iopub.execute_input": "2025-01-16T21:25:47.931063Z",
     "iopub.status.idle": "2025-01-16T21:25:47.955027Z",
     "shell.execute_reply.started": "2025-01-16T21:25:47.931035Z",
     "shell.execute_reply": "2025-01-16T21:25:47.954252Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:51:56.297507Z",
     "start_time": "2025-01-17T18:47:50.066785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              question  \\\n",
       "0    «Сміхом крізь сльози» можна схарактеризувати з...   \n",
       "1    Удовин син, мати, сестра, кохана – ключові обр...   \n",
       "2    В уривку з історичного джерела «*Створивши бан...   \n",
       "3    В уривку\\n\\n\\n*Доки буде жити Україна\\n\\nВ теп...   \n",
       "4    Букву ***и*** на місці пропуску треба писати в...   \n",
       "..                                                 ...   \n",
       "746  Укажіть правильний варіант послідовного заповн...   \n",
       "747  **Проаналізуйте фрагмент історичного документа...   \n",
       "748  Прочитайте речення *(цифра позначає наступне с...   \n",
       "749  Граматично правильне продовження речення «*Пер...   \n",
       "750  Прочитайте уривок джерела.\\n\\n\\n«*У Московщині...   \n",
       "\n",
       "                                               answers  \\\n",
       "0    [{'marker': 'А', 'text': '«Три зозулі з поклон...   \n",
       "1    [{'marker': 'А', 'text': '«Засвіт встали козач...   \n",
       "2    [{'marker': 'А', 'text': 'Правобережної Україн...   \n",
       "3    [{'marker': 'А', 'text': 'Василя Стефаника'}, ...   \n",
       "4    [{'marker': 'А', 'text': 'пр….хований, пр…звис...   \n",
       "..                                                 ...   \n",
       "746  [{'marker': 'А', 'text': 'дієвих прийомів, які...   \n",
       "747  [{'marker': 'А', 'text': 'Українська головна в...   \n",
       "748  [{'marker': 'А', 'text': '3, 4, 5, 10'}, {'mar...   \n",
       "749  [{'marker': 'А', 'text': 'мені пригадалися дав...   \n",
       "750  [{'marker': 'А', 'text': 'Зборівського договор...   \n",
       "\n",
       "                               subject   id correct_answers  \n",
       "0    ukrainian-language-and-literature    0             [Б]  \n",
       "1    ukrainian-language-and-literature    1             [Г]  \n",
       "2                   history-of-ukraine    2             [Г]  \n",
       "3    ukrainian-language-and-literature    3             [Д]  \n",
       "4    ukrainian-language-and-literature    4             [В]  \n",
       "..                                 ...  ...             ...  \n",
       "746  ukrainian-language-and-literature  746             [Г]  \n",
       "747                 history-of-ukraine  747             [Г]  \n",
       "748  ukrainian-language-and-literature  748             [Г]  \n",
       "749  ukrainian-language-and-literature  749             [Д]  \n",
       "750                 history-of-ukraine  750             [А]  \n",
       "\n",
       "[751 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>subject</th>\n",
       "      <th>id</th>\n",
       "      <th>correct_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>«Сміхом крізь сльози» можна схарактеризувати з...</td>\n",
       "      <td>[{'marker': 'А', 'text': '«Три зозулі з поклон...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>0</td>\n",
       "      <td>[Б]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Удовин син, мати, сестра, кохана – ключові обр...</td>\n",
       "      <td>[{'marker': 'А', 'text': '«Засвіт встали козач...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>1</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В уривку з історичного джерела «*Створивши бан...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Правобережної Україн...</td>\n",
       "      <td>history-of-ukraine</td>\n",
       "      <td>2</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В уривку\\n\\n\\n*Доки буде жити Україна\\n\\nВ теп...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Василя Стефаника'}, ...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>3</td>\n",
       "      <td>[Д]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Букву ***и*** на місці пропуску треба писати в...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'пр….хований, пр…звис...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>4</td>\n",
       "      <td>[В]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Укажіть правильний варіант послідовного заповн...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'дієвих прийомів, які...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>746</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>**Проаналізуйте фрагмент історичного документа...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Українська головна в...</td>\n",
       "      <td>history-of-ukraine</td>\n",
       "      <td>747</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Прочитайте речення *(цифра позначає наступне с...</td>\n",
       "      <td>[{'marker': 'А', 'text': '3, 4, 5, 10'}, {'mar...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>748</td>\n",
       "      <td>[Г]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Граматично правильне продовження речення «*Пер...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'мені пригадалися дав...</td>\n",
       "      <td>ukrainian-language-and-literature</td>\n",
       "      <td>749</td>\n",
       "      <td>[Д]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Прочитайте уривок джерела.\\n\\n\\n«*У Московщині...</td>\n",
       "      <td>[{'marker': 'А', 'text': 'Зборівського договор...</td>\n",
       "      <td>history-of-ukraine</td>\n",
       "      <td>750</td>\n",
       "      <td>[А]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "submission_df['correct_answers'] = submission_df['correct_answers'].apply(lambda x: x[0])\n",
    "submission_df[[\"id\", \"correct_answers\"]].to_csv(\"submission.csv\", index=False)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-16T21:26:21.873889Z",
     "iopub.execute_input": "2025-01-16T21:26:21.874197Z",
     "iopub.status.idle": "2025-01-16T21:26:21.880935Z",
     "shell.execute_reply.started": "2025-01-16T21:26:21.874174Z",
     "shell.execute_reply": "2025-01-16T21:26:21.879772Z"
    },
    "ExecuteTime": {
     "end_time": "2025-01-17T18:54:20.648003Z",
     "start_time": "2025-01-17T18:54:20.643808Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
